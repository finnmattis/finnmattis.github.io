# EvidenceBench: benchmark thing

EvidenceBench is a comprehensive benchmark designed for extracting evidence from biomedical papers, specifically targeting the validation of scientific hypotheses. Developed by a team of experts, it includes over 400 fully annotated papers and 700,000 sentence judgments, leveraging expert annotations to match hypotheses with relevant evidence. The benchmark aims to automate evidence synthesis and hypothesis testing, utilizing a pipeline powered by Large Language Models (LLMs) to align hypotheses with evidence from papers. This dataset supports the development of advanced tools for long-context reasoning and retrieval in biomedical research, offering a standardized framework for evaluating language models and information retrieval systems.